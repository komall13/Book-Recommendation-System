# -*- coding: utf-8 -*-
"""Book Recommendation System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15T4ZVqWLsvV8raexMyUUSKOA87Ex4Buc

1.Analyzing Data
"""

import pandas as pd
import numpy as np
import chardet
import seaborn as sns
import matplotlib.pyplot as plt

"""1.1 Read books csv"""

from google.colab import drive
drive.mount('/content/drive')

df_books = pd.read_csv('/content/drive/MyDrive/BigData/books_data.csv')
df_books.head()

df_books = df_books[[ 'Title', 'authors', 'image', 'categories']].copy()
df_books.rename(columns={
    'Title': 'title'
}, inplace=True)
df_books

"""1.2 Read ratings csv"""

df_ratings = pd.read_csv('/content/drive/MyDrive/BigData/Books_rating.csv')
df_ratings.head()

df_ratings = df_ratings[[ 'Title', 'User_id', 'review/score']].copy()
df_ratings.rename(columns={
    'Title': 'title',
    'User_id' : 'user_id',
    'review/score' : 'rating'

}, inplace=True)
df_ratings.dropna(inplace=True)
df_ratings

df_ratings.describe()

print(len(df_ratings['user_id'].unique()))

user_rating_count = df_ratings.groupby('user_id').size().sort_values(ascending=False)
user_rating_count

book_rating_count = df_ratings.groupby('title').size().sort_values(ascending=False)
book_rating_count

while True:
    book_rating_count = df_ratings['title'].value_counts()
    filtered_books = book_rating_count[book_rating_count > 20].index
    user_rating_count = df_ratings[df_ratings['title'].isin(filtered_books)]['user_id'].value_counts()
    filtered_users = user_rating_count[user_rating_count > 20].index
    df_ratings_filtered = df_ratings[
        df_ratings['title'].isin(filtered_books) &
        df_ratings['user_id'].isin(filtered_users)
    ]
    if len(df_ratings_filtered) == len(df_ratings):
        break

    # Cập nhật df_ratings để tiếp tục lọc nếu chưa thỏa mãn
    df_ratings = df_ratings_filtered.copy()
df_ratings_filtered.reset_index(drop=True, inplace=True)
print(df_ratings_filtered)

user_rating_count = df_ratings.groupby('user_id').size().sort_values(ascending=False)
user_rating_count

book_rating_count = df_ratings.groupby('title').size().sort_values(ascending=False)
book_rating_count

sns.histplot(df_ratings['rating'], bins = 5)

"""2.PreProcessingData

2.1 Encoding Columns
"""

book_index = {book: idx for idx, book in enumerate(df_ratings['title'].unique())}
book_index.get('Pride and Prejudice')

user_index = {user: idx for idx, user in enumerate(df_ratings['user_id'].unique())}
user_index.get('A30TK6U7DNS82R')

df_ratings.loc[:, 'book_index'] = df_ratings['title'].map(book_index)
df_ratings.loc[:, 'user_index'] = df_ratings['user_id'].map(user_index)

df_ratings.to_csv('/content/drive/MyDrive/BigData/processed_ratings.csv', index=False)

# save books detail
filtered_books = df_books[df_books['title'].isin(df_ratings['title'].unique())]
filtered_books = filtered_books.merge(
    df_ratings[['title', 'book_index']].drop_duplicates(),
    on='title',
    how='left'
)
filtered_books.to_csv('/content/drive/MyDrive/BigData/books.csv', index=False)


print(df_ratings)

book_pivot = df_ratings.pivot_table(columns='user_index', index='book_index', values="rating")
book_pivot.head(100)

book_pivot.fillna(0,inplace=True)
book_pivot.head()

"""Train"""

from scipy.sparse import csr_matrix
book_sparse = csr_matrix(book_pivot)

from sklearn.neighbors import NearestNeighbors
model = NearestNeighbors(algorithm='brute')
model.fit(book_sparse)

distances, suggestions = model.kneighbors(book_pivot.iloc[237, :].values.reshape(1, -1), n_neighbors=6)
distances

suggestions

for i in range(len(suggestions)):
  print(book_pivot.index[suggestions[i]])

book_pivot.index[3]

import pickle
pickle.dump(model, open('/content/drive/MyDrive/BigData/model.pkl', 'wb'))
# pickle.dump(books_name, open('/content/drive/MyDrive/BigData/books_name.pkl', 'wb'))
# pickle.dump(final_rating, open('/content/drive/MyDrive/BigData/final_rating.pkl', 'wb'))
pickle.dump(book_pivot, open('/content/drive/MyDrive/BigData/book_pivot.pkl', 'wb'))

def recommend_book(book_index):
  book_id = np.where(book_pivot.index == book_index)[0][0]
  distances, suggestions = model.kneighbors(book_pivot.iloc[book_id, :].values.reshape(1, -1), n_neighbors=6)

  for i in range(len(suggestions)):
    books = book_pivot.index[suggestions[i]]
    for j in books:
      print(j)

idsach = int(input("Please enter the book index: "))
# name_book = "A Bend in the Road"
recommend_book(idsach)

from sklearn.neighbors import NearestNeighbors
from scipy.sparse import csr_matrix

# Create pivot table (Utility matrix)
book_user_matrix = df_ratings_filtered.pivot_table(index='title', columns='user_id', values='rating').fillna(0)

# Convert to sparse matrix
book_user_sparse = csr_matrix(book_user_matrix.values)

# Fit the KNN model
model_knn = NearestNeighbors(metric='cosine', algorithm='brute')
model_knn.fit(book_user_sparse)

def get_book_recommendations(book_name, n_recommendations=5):
    if book_name not in book_user_matrix.index:
        return f"Book '{book_name}' not found in dataset."

    book_index = book_user_matrix.index.get_loc(book_name)
    distances, indices = model_knn.kneighbors(book_user_matrix.iloc[book_index, :].values.reshape(1, -1), n_neighbors=n_recommendations+1)

    recommendations = []
    for i in range(1, len(distances[0])):
        rec_title = book_user_matrix.index[indices[0][i]]
        recommendations.append((rec_title, distances[0][i]))

    return recommendations

recs = get_book_recommendations("Pride and Prejudice", 5)
for book, score in recs:
    print(f"{book} - Similarity Score: {score:.4f}")